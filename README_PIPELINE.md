# Pipeline de Reconnaissance LSF (Langue des Signes FranÃ§aise)

Ce pipeline complet permet de traiter des vidÃ©os de langue des signes franÃ§aise pour crÃ©er un dataset optimisÃ© pour l'entraÃ®nement de modÃ¨les de reconnaissance.

## ğŸ¯ Objectif

Transformer des vidÃ©os brutes de signes LSF en un dataset structurÃ© avec :
- Extraction de landmarks 3D (pose, visage, mains) via MediaPipe Holistic
- SÃ©paration intelligente train/validation/test par source
- Augmentation de donnÃ©es sophistiquÃ©e
- Structure optimisÃ©e pour l'entraÃ®nement

## ğŸ“ Structure du Projet

```
lsf-recognition/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                          # VidÃ©os brutes
â”‚   â”‚   â”œâ”€â”€ parlr/jauvert/           # Source 1
â”‚   â”‚   â”œâ”€â”€ parlr/elix/              # Source 2
â”‚   â”‚   â”œâ”€â”€ parlr/education-nationale/ # Source 3
â”‚   â”‚   â””â”€â”€ custom/                   # Source 4
â”‚   â”œâ”€â”€ processed/                    # Landmarks extraits
â”‚   â”‚   â”œâ”€â”€ bonjour/
â”‚   â”‚   â”‚   â”œâ”€â”€ jauvert.npy
â”‚   â”‚   â”‚   â”œâ”€â”€ jauvert_metadata.json
â”‚   â”‚   â”‚   â”œâ”€â”€ elix.npy
â”‚   â”‚   â”‚   â””â”€â”€ elix_metadata.json
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ train/                        # DonnÃ©es d'entraÃ®nement (avec augmentation)
â”‚   â”œâ”€â”€ val/                          # DonnÃ©es de validation
â”‚   â”œâ”€â”€ test/                         # DonnÃ©es de test
â”‚   â””â”€â”€ corpus.txt                    # Liste des signes
â”œâ”€â”€ src/
â”‚   â””â”€â”€ data_processing/
â”‚       â”œâ”€â”€ extract_landmarks.py
â”‚       â”œâ”€â”€ consolidate.py
â”‚       â”œâ”€â”€ augment.py
â”‚       â”œâ”€â”€ visualize_landmarks.py
â”‚       â””â”€â”€ run_pipeline.py
â””â”€â”€ visualizations/                   # Visualisations gÃ©nÃ©rÃ©es
```

## ğŸš€ Utilisation Rapide

### 1. PrÃ©paration des donnÃ©es

Placez vos vidÃ©os dans la structure suivante :
```
data/raw/
â”œâ”€â”€ parlr/jauvert/
â”‚   â”œâ”€â”€ bonjour.webm
â”‚   â”œâ”€â”€ merci.webm
â”‚   â””â”€â”€ ...
â”œâ”€â”€ parlr/elix/
â”‚   â”œâ”€â”€ bonjour.webm
â”‚   â”œâ”€â”€ au_revoir.webm
â”‚   â””â”€â”€ ...
â””â”€â”€ ...
```

### 2. ExÃ©cution du pipeline complet

```bash
# Pipeline complet
python src/data_processing/run_pipeline.py

# Ou par Ã©tapes
python src/data_processing/run_pipeline.py --skip-extraction      # Si landmarks dÃ©jÃ  extraits
python src/data_processing/run_pipeline.py --skip-consolidation   # Si splits dÃ©jÃ  crÃ©Ã©s
python src/data_processing/run_pipeline.py --skip-augmentation    # Si pas d'augmentation
```

### 3. Visualisation des rÃ©sultats

```bash
# Visualiser un Ã©chantillon
python src/data_processing/visualize_landmarks.py --data-path processed

# Visualiser des donnÃ©es spÃ©cifiques
python src/data_processing/visualize_landmarks.py --data-path train --sign-name bonjour --source-name jauvert
```

## ğŸ”§ Ã‰tapes du Pipeline

### 1. Extraction des Landmarks (`extract_landmarks.py`)

**Objectif** : Extraire les landmarks 3D de chaque vidÃ©o

**FonctionnalitÃ©s** :
- Utilise MediaPipe Holistic pour dÃ©tecter pose, visage, mains
- Sauvegarde landmarks + mÃ©tadonnÃ©es (confiance, FPS, etc.)
- Structure : `processed/{sign}/{source}.npy`
- Analyse automatique de la distribution des sources

**Format des landmarks** :
```python
# Shape: (num_frames, total_landmarks)
# Structure:
# - Pose: 33 points Ã— 4 (x, y, z, visibility)
# - Face: 468 points Ã— 3 (x, y, z)
# - Main gauche: 21 points Ã— 3 (x, y, z)
# - Main droite: 21 points Ã— 3 (x, y, z)
# Total: 33*4 + 468*3 + 21*3 + 21*3 = 1662 dimensions
```

### 2. Consolidation et Splits (`consolidate.py`)

**Objectif** : CrÃ©er les splits train/val/test avec sÃ©paration par source

**StratÃ©gie de sÃ©paration** :
- **Signes multi-sources** :
  - 2 sources : 1 train, 1 test
  - 3 sources : 1 train, 1 val, 1 test
- **Signes mono-source** : Tout en train (pas de test)
- **Filtrage qualitÃ©** : Seuil de confiance minimum

**Avantages** :
- Ã‰vite le data leakage entre sources
- Test sur sources non vues pendant l'entraÃ®nement
- Ã‰valuation plus rÃ©aliste de la gÃ©nÃ©ralisation

### 3. Augmentation des DonnÃ©es (`augment.py`)

**Objectif** : GÃ©nÃ©rer des versions augmentÃ©es pour l'entraÃ®nement

**Techniques d'augmentation** :
- **Spatiale** : Rotation, Ã©chelle, translation
- **Temporelle** : Variation de vitesse, suppression de frames
- **Occlusion** : Simulation d'occlusion partielle
- **Perspective** : Changement de point de vue
- **Mixup** : MÃ©lange avec version bruitÃ©e

**Configuration** :
- 5 versions augmentÃ©es par original (configurable)
- Seulement sur les donnÃ©es d'entraÃ®nement
- MÃ©tadonnÃ©es prÃ©servÃ©es avec info d'augmentation

## ğŸ“Š MÃ©tadonnÃ©es et QualitÃ©

### MÃ©tadonnÃ©es par vidÃ©o
```json
{
  "video_path": "path/to/video.webm",
  "fps": 30.0,
  "frame_count": 90,
  "width": 1920,
  "height": 1080,
  "extracted_frames": 90,
  "average_pose_confidence": 0.85,
  "average_face_confidence": 1.0,
  "average_left_hand_confidence": 0.92,
  "average_right_hand_confidence": 0.88,
  "frame_metadata": [...]
}
```

### MÃ©tadonnÃ©es par frame
```json
{
  "frame_index": 0,
  "pose_confidence": 0.87,
  "face_confidence": 1.0,
  "left_hand_confidence": 0.95,
  "right_hand_confidence": 0.91
}
```

## ğŸ¨ Visualisation

Le script `visualize_landmarks.py` permet de :

1. **Visualiser un frame** : Points colorÃ©s par type (pose, visage, mains)
2. **CrÃ©er des animations** : VidÃ©os MP4 des landmarks
3. **Analyser la confiance** : Graphiques de confiance dans le temps
4. **Comparer original vs augmentÃ©** : Side-by-side des versions

### Utilisation
```bash
# Visualiser un Ã©chantillon automatique
python src/data_processing/visualize_landmarks.py

# Visualiser des donnÃ©es spÃ©cifiques
python src/data_processing/visualize_landmarks.py \
  --data-path train \
  --sign-name bonjour \
  --source-name jauvert \
  --output-dir ./my_visualizations
```

## âš™ï¸ Configuration

### ParamÃ¨tres d'extraction
```python
# Dans extract_landmarks.py
min_detection_confidence = 0.5
min_tracking_confidence = 0.5
model_complexity = 1  # 0, 1, ou 2
```

### ParamÃ¨tres de consolidation
```python
# Dans consolidate.py
min_confidence = 0.3  # Seuil de qualitÃ© minimum
```

### ParamÃ¨tres d'augmentation
```python
# Dans augment.py
augmentation_factor = 5  # Nombre de versions augmentÃ©es
```

## ğŸ“ˆ Statistiques du Dataset

Le pipeline gÃ©nÃ¨re automatiquement des statistiques :

- **Distribution des sources** : Nombre de signes par source
- **QualitÃ© des landmarks** : Scores de confiance moyens
- **Splits** : Nombre de signes par split
- **Augmentation** : Nombre de versions gÃ©nÃ©rÃ©es

## ğŸ” DÃ©pannage

### ProblÃ¨mes courants

1. **MediaPipe non installÃ©** :
   ```bash
   pip install mediapipe
   ```

2. **VidÃ©os non trouvÃ©es** :
   - VÃ©rifiez la structure des dossiers
   - Formats supportÃ©s : `.webm`, `.mp4`, `.avi`, `.mov`

3. **MÃ©moire insuffisante** :
   - RÃ©duisez `model_complexity` dans MediaPipe
   - Traitez par petits lots

4. **Erreurs de landmarks** :
   - VÃ©rifiez la qualitÃ© des vidÃ©os
   - Augmentez `min_detection_confidence`

### Logs et monitoring

- **Logs** : `pipeline.log` dans le rÃ©pertoire d'exÃ©cution
- **Progression** : Affichage en temps rÃ©el
- **Erreurs** : DÃ©tails complets dans les logs

## ğŸ¯ Prochaines Ã‰tapes

1. **EntraÃ®nement du modÃ¨le** : Utiliser les donnÃ©es gÃ©nÃ©rÃ©es
2. **Ã‰valuation** : Tester sur le split test
3. **AmÃ©lioration** : Ajuster les paramÃ¨tres selon les rÃ©sultats
4. **DÃ©ploiement** : IntÃ©grer dans une application

## ğŸ“ Notes Techniques

- **Performance** : Extraction ~1-2s par vidÃ©o (selon la durÃ©e)
- **Stockage** : ~1-5MB par vidÃ©o (selon le nombre de frames)
- **CompatibilitÃ©** : Python 3.8+, Linux/macOS/Windows
- **DÃ©pendances** : Voir `requirements.txt`

---

**Pipeline dÃ©veloppÃ© pour la reconnaissance LSF avec focus sur la robustesse et la gÃ©nÃ©ralisation.** 