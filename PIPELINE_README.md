# ğŸš€ Pipeline Complet LSF - Guide d'Utilisation

## ğŸ“‹ Vue d'ensemble

Ce pipeline complet traite automatiquement vos vidÃ©os LSF pour crÃ©er un dataset robuste et gÃ©nÃ©ralisable pour l'entraÃ®nement d'un modÃ¨le de reconnaissance de langue des signes franÃ§aise.

## ğŸ¯ FonctionnalitÃ©s

### âœ… **Extraction AvancÃ©e des Landmarks**
- Utilise MediaPipe Holistic pour extraire les landmarks du corps, visage et mains
- PrÃ©serve les mÃ©tadonnÃ©es (confiance, FPS, dimensions)
- Gestion intelligente des erreurs et reprise automatique

### âœ… **Consolidation Intelligente**
- Analyse automatique des sources multiples (jauvert, elix, education-nationale)
- SÃ©paration par source pour Ã©viter le "data leakage"
- Filtrage par qualitÃ© des landmarks extraits
- GÃ©nÃ©ration automatique du corpus

### âœ… **Augmentation SophistiquÃ©e**
- **Spatiale** : rotation, translation, mise Ã  l'Ã©chelle, perspective
- **Temporelle** : warping temporel, bruit temporel
- **Occlusion** : simulation d'occlusions partielles
- **Mixup** : mÃ©lange entre sÃ©quences similaires
- **15 versions augmentÃ©es** par Ã©chantillon original

### âœ… **SÃ©paration Optimale Train/Val/Test**
- **Signes multi-sources** : sÃ©paration stricte par source
- **Signes uniques** : augmentation maximale pour enrichir le train
- **Ã‰vite le data leakage** pour une Ã©valuation fiable

## ğŸ› ï¸ Installation

```bash
# Installer les dÃ©pendances
pip install -r requirements.txt
```

## ğŸš€ Utilisation

### Lancement Simple
```bash
# Pipeline complet avec paramÃ¨tres par dÃ©faut
python run_pipeline.py

# Avec facteur d'augmentation personnalisÃ©
python run_pipeline.py --augmentation-factor 20

# Forcer le retraitement des vidÃ©os dÃ©jÃ  traitÃ©es
python run_pipeline.py --force-reprocess
```

### Lancement AvancÃ©
```bash
# Utiliser le script principal directement
python src/data_processing/pipeline_complet.py --augmentation-factor 15 --force-reprocess
```

## ğŸ“ Structure des DonnÃ©es

### EntrÃ©e (VidÃ©os Sources)
```
data/raw/
â”œâ”€â”€ parlr/
â”‚   â”œâ”€â”€ jauvert/          # ~100 vidÃ©os .webm
â”‚   â”œâ”€â”€ elix/             # ~100 vidÃ©os .webm
â”‚   â””â”€â”€ education-nationale/  # ~100 vidÃ©os .webm
â””â”€â”€ custom/               # VidÃ©os personnalisÃ©es
```

### Sortie (Dataset Final)
```
data/
â”œâ”€â”€ corpus.txt                    # Liste des signes
â”œâ”€â”€ quality_metrics.json          # MÃ©triques de qualitÃ©
â”œâ”€â”€ split_assignments.json        # Assignations train/val/test
â”œâ”€â”€ dataset_statistics.json       # Statistiques finales
â”œâ”€â”€ final_train/                  # DonnÃ©es d'entraÃ®nement augmentÃ©es
â”œâ”€â”€ final_val/                    # DonnÃ©es de validation
â””â”€â”€ final_test/                   # DonnÃ©es de test
```

## âš™ï¸ ParamÃ¨tres Configurables

### Facteur d'Augmentation
- **DÃ©faut** : 15 versions par Ã©chantillon original
- **RecommandÃ©** : 10-20 selon la puissance de calcul disponible
- **Impact** : Plus d'augmentation = meilleure gÃ©nÃ©ralisation mais temps de traitement plus long

### Seuil de QualitÃ©
- **DÃ©faut** : 0.3 (30% de confiance minimale)
- **Impact** : Filtre les landmarks de mauvaise qualitÃ©

### SÃ©paration Train/Val/Test
- **Train** : 70% des sources + donnÃ©es augmentÃ©es
- **Validation** : 10% des sources
- **Test** : 20% des sources

## ğŸ“Š MÃ©triques de QualitÃ©

Le pipeline gÃ©nÃ¨re automatiquement :

1. **Corpus** : Liste des signes de haute qualitÃ©
2. **MÃ©triques par signe** :
   - Confiance moyenne des landmarks
   - Nombre de sources
   - Nombre d'Ã©chantillons
3. **Statistiques par split** :
   - Nombre de signes
   - Nombre total d'Ã©chantillons
   - Distribution par signe

## ğŸ”§ Techniques d'Augmentation

### Spatiales
- **Bruit gaussien** : Â±0.01 sur les coordonnÃ©es
- **Translation** : Â±0.05 en x, y, z
- **Rotation** : Â±15Â° autour de l'axe Y
- **Mise Ã  l'Ã©chelle** : Â±10% uniforme
- **Perspective** : Simulation d'angles de vue

### Temporelles
- **Warping temporel** : Â±20% de variation de vitesse
- **Bruit temporel** : Variations fluides dans le temps
- **Occlusion partielle** : 30% de chance d'occlusion par frame

### AvancÃ©es
- **Mixup** : MÃ©lange entre sÃ©quences similaires
- **Combinaisons alÃ©atoires** : Application probabiliste des augmentations

## âš¡ Performance

### Temps EstimÃ©s (sur CPU standard)
- **Extraction** : ~2-3 secondes par vidÃ©o
- **Consolidation** : ~30 secondes
- **Augmentation** : ~1-2 secondes par Ã©chantillon
- **Total** : ~2-4 heures pour 1000+ vidÃ©os

### Optimisations
- **Reprise automatique** : Le pipeline reprend oÃ¹ il s'est arrÃªtÃ©
- **Traitement parallÃ¨le** : PossibilitÃ© d'ajouter du multiprocessing
- **MÃ©moire optimisÃ©e** : Traitement par batch pour Ã©viter l'overflow

## ğŸ› DÃ©pannage

### Erreurs Courantes

1. **"Could not open video"**
   - VÃ©rifiez que les vidÃ©os sont dans le bon format (.webm, .mp4, .avi, .mov)
   - VÃ©rifiez les permissions de lecture

2. **"No landmarks extracted"**
   - VidÃ©o de mauvaise qualitÃ© ou trop courte
   - Personne non visible ou trop loin de la camÃ©ra

3. **"Import error"**
   - VÃ©rifiez que toutes les dÃ©pendances sont installÃ©es
   - VÃ©rifiez que tous les fichiers du pipeline sont prÃ©sents

### Logs
- **pipeline.log** : Logs dÃ©taillÃ©s du traitement
- **Console** : Progression en temps rÃ©el

## ğŸ¯ RÃ©sultat Final

AprÃ¨s exÃ©cution du pipeline, vous aurez :

1. **Dataset robuste** : ~15,000+ Ã©chantillons augmentÃ©s
2. **SÃ©paration propre** : Train/val/test sans data leakage
3. **Corpus optimisÃ©** : Signes de haute qualitÃ© uniquement
4. **MÃ©tadonnÃ©es complÃ¨tes** : Pour analyse et debug

## ğŸš€ Prochaines Ã‰tapes

1. **EntraÃ®nement du modÃ¨le** : Utiliser `data/final_train/` et `data/final_val/`
2. **Ã‰valuation** : Tester sur `data/final_test/`
3. **Analyse** : Consulter `dataset_statistics.json` pour les mÃ©triques

---

**ğŸ‰ Votre dataset est maintenant prÃªt pour entraÃ®ner un modÃ¨le robuste et gÃ©nÃ©ralisable !** 